{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3621720-533c-47c1-8194-70f3a25f1465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeetCode-style PySpark datasets loaded and registered.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# LeetCode-Style Practice Dataset for PySpark\n",
    "# Target: PySpark (Spark 3.x)\n",
    "# Purpose: Same logical data as SQL Server dataset\n",
    "# =====================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LeetCodeStyleSQLDataset\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# ---------------------\n",
    "# Departments\n",
    "# ---------------------\n",
    "departments_schema = StructType([\n",
    "    StructField(\"DeptId\", IntegerType(), False),\n",
    "    StructField(\"DeptName\", StringType(), True)\n",
    "])\n",
    "\n",
    "departments_data = [\n",
    "    (1, \"IT\"),\n",
    "    (2, \"HR\"),\n",
    "    (3, \"Sales\")\n",
    "]\n",
    "\n",
    "Departments = spark.createDataFrame(departments_data, departments_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Employees\n",
    "# ---------------------\n",
    "employees_schema = StructType([\n",
    "    StructField(\"EmpId\", IntegerType(), False),\n",
    "    StructField(\"EmpName\", StringType(), True),\n",
    "    StructField(\"Salary\", IntegerType(), True),\n",
    "    StructField(\"DeptId\", IntegerType(), True),\n",
    "    StructField(\"ManagerId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "employees_data = [\n",
    "    (1, \"Alice\", 90000, 1, None),\n",
    "    (2, \"Bob\", 80000, 1, 1),\n",
    "    (3, \"Charlie\", 80000, 1, 1),\n",
    "    (4, \"David\", 60000, 2, None),\n",
    "    (5, \"Eva\", 70000, None, None),\n",
    "    (6, \"Frank\", 90000, 3, None)\n",
    "]\n",
    "\n",
    "Employees = spark.createDataFrame(employees_data, employees_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Customers\n",
    "# ---------------------\n",
    "customers_schema = StructType([\n",
    "    StructField(\"CustomerId\", IntegerType(), False),\n",
    "    StructField(\"CustomerName\", StringType(), True)\n",
    "])\n",
    "\n",
    "customers_data = [\n",
    "    (1, \"John\"),\n",
    "    (2, \"Jane\"),\n",
    "    (3, \"Alex\")\n",
    "]\n",
    "\n",
    "Customers = spark.createDataFrame(customers_data, customers_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Products\n",
    "# ---------------------\n",
    "products_schema = StructType([\n",
    "    StructField(\"ProductId\", IntegerType(), False),\n",
    "    StructField(\"ProductName\", StringType(), True),\n",
    "    StructField(\"Price\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "products_data = [\n",
    "    (1, \"Laptop\", 1000),\n",
    "    (2, \"Phone\", 500),\n",
    "    (3, \"Tablet\", 300)\n",
    "]\n",
    "\n",
    "Products = spark.createDataFrame(products_data, products_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Orders\n",
    "# ---------------------\n",
    "orders_schema = StructType([\n",
    "    StructField(\"OrderId\", IntegerType(), False),\n",
    "    StructField(\"CustomerId\", IntegerType(), True),\n",
    "    StructField(\"ProductId\", IntegerType(), True),\n",
    "    StructField(\"OrderDate\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "orders_data = [\n",
    "    (1, 1, 1, \"2024-01-01\", 1),\n",
    "    (2, 1, 2, \"2024-01-02\", 2),\n",
    "    (3, 2, 2, \"2024-01-03\", 1),\n",
    "    (4, 2, 3, \"2024-01-10\", 3),\n",
    "    (5, 3, 1, \"2024-01-11\", 1)\n",
    "]\n",
    "\n",
    "Orders = spark.createDataFrame(orders_data, orders_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Logs\n",
    "# ---------------------\n",
    "logs_schema = StructType([\n",
    "    StructField(\"LogId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "logs_data = [(1,), (1,), (2,), (3,), (3,), (3,), (5,), (6,)]\n",
    "\n",
    "Logs = spark.createDataFrame(logs_data, logs_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Stadium\n",
    "# ---------------------\n",
    "stadium_schema = StructType([\n",
    "    StructField(\"VisitDate\", StringType(), True),\n",
    "    StructField(\"People\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "stadium_data = [\n",
    "    (\"2024-01-01\", 10),\n",
    "    (\"2024-01-02\", 120),\n",
    "    (\"2024-01-03\", 130),\n",
    "    (\"2024-01-04\", 140),\n",
    "    (\"2024-01-05\", 20)\n",
    "]\n",
    "\n",
    "Stadium = spark.createDataFrame(stadium_data, stadium_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Users\n",
    "# ---------------------\n",
    "users_schema = StructType([\n",
    "    StructField(\"UserId\", IntegerType(), False),\n",
    "    StructField(\"Banned\", StringType(), True)\n",
    "])\n",
    "\n",
    "users_data = [\n",
    "    (1, \"No\"),\n",
    "    (2, \"Yes\"),\n",
    "    (3, \"No\"),\n",
    "    (4, \"No\")\n",
    "]\n",
    "\n",
    "Users = spark.createDataFrame(users_data, users_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Trips\n",
    "# ---------------------\n",
    "trips_schema = StructType([\n",
    "    StructField(\"TripId\", IntegerType(), False),\n",
    "    StructField(\"ClientId\", IntegerType(), True),\n",
    "    StructField(\"DriverId\", IntegerType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"RequestDate\", StringType(), True)\n",
    "])\n",
    "\n",
    "trips_data = [\n",
    "    (1, 1, 3, \"completed\", \"2024-01-01\"),\n",
    "    (2, 2, 3, \"cancelled_by_driver\", \"2024-01-01\"),\n",
    "    (3, 1, 4, \"cancelled_by_client\", \"2024-01-02\"),\n",
    "    (4, 3, 4, \"completed\", \"2024-01-02\")\n",
    "]\n",
    "\n",
    "Trips = spark.createDataFrame(trips_data, trips_schema)\n",
    "\n",
    "# ---------------------\n",
    "# Movies\n",
    "# ---------------------\n",
    "movies_schema = StructType([\n",
    "    StructField(\"MovieId\", IntegerType(), False),\n",
    "    StructField(\"Title\", StringType(), True)\n",
    "])\n",
    "\n",
    "movies_data = [\n",
    "    (1, \"Inception\"),\n",
    "    (2, \"Interstellar\"),\n",
    "    (3, \"Dunkirk\")\n",
    "]\n",
    "\n",
    "Movies = spark.createDataFrame(movies_data, movies_schema)\n",
    "\n",
    "# ---------------------\n",
    "# MovieRatings\n",
    "# ---------------------\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"MovieId\", IntegerType(), True),\n",
    "    StructField(\"UserId\", IntegerType(), True),\n",
    "    StructField(\"Rating\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "ratings_data = [\n",
    "    (1, 1, 5),\n",
    "    (1, 2, 4),\n",
    "    (2, 1, 5),\n",
    "    (2, 3, 5),\n",
    "    (3, 2, 3)\n",
    "]\n",
    "\n",
    "MovieRatings = spark.createDataFrame(ratings_data, ratings_schema)\n",
    "\n",
    "print(\"LeetCode-style PySpark datasets loaded and registered.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcdc4fb-6e1b-4c91-8f59-059f43e7d0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+------+---------+\n",
      "|EmpId|EmpName|Salary|DeptId|ManagerId|\n",
      "+-----+-------+------+------+---------+\n",
      "|    1|  Alice| 90000|     1|     null|\n",
      "|    2|    Bob| 80000|     1|        1|\n",
      "|    3|Charlie| 80000|     1|        1|\n",
      "|    4|  David| 60000|     2|     null|\n",
      "|    5|    Eva| 70000|  null|     null|\n",
      "|    6|  Frank| 90000|     3|     null|\n",
      "+-----+-------+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Employees.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57a7fb7-b96f-4fac-841a-b8f9ee647456",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1 — Second Highest Salary (Tie-aware)\n",
    "\n",
    "Using the `Employees` table, return the **second highest distinct salary**.\n",
    "\n",
    "Constraints:\n",
    "\n",
    "- If there is no second highest salary, return `NULL`.\n",
    "- Duplicate salaries must not create false ranks.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- `SecondHighestSalary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a40937-d873-4682-8752-84256cbfc12e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|SecondHighestSalary|\n",
      "+-------------------+\n",
      "|              80000|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy(desc(col('Salary')))\n",
    "emp = Employees.select('Salary').distinct()\n",
    "emp = emp.withColumn('rn', row_number().over(window_spec)).filter((col('rn')==2)).withColumnRenamed('Salary','SecondHighestSalary').drop('rn')\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66265e2-e236-4829-b6a2-843ac0b43595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Question 2 — Employees Earning More Than Their Manager\n",
    "\n",
    "From the `Employees` table, list employees who earn **strictly more** than their manager.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Some employees have no manager.\n",
    "- Managers are also employees.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- `EmpName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa75a71-30fc-4e11-be2e-450f94e7ea85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|EmpName|\n",
      "+-------+\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = Employees.alias('e1').join(Employees.alias('e2'), on = col(\"e1.EmpId\") == col(\"e2.ManagerId\"), how = 'inner').filter(col('e1.Salary')<col('e2.Salary')).select('e2.EmpName')\n",
    "emp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272ae82-08f3-4ce7-9bd7-a8224134372c",
   "metadata": {},
   "source": [
    "### Question 3 — Customers Who Never Ordered\n",
    "\n",
    "Using `Customers` and `Orders`, find customers who **never placed an order**.\n",
    "\n",
    "Constraints:\n",
    "\n",
    "- Do not assume referential completeness.\n",
    "- Avoid false positives caused by joins.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- `CustomerName`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8104ae2-dbd4-4bb6-863a-171b79bacba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|CustomerName|\n",
      "+------------+\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust = Customers.alias('c').join(Orders.alias('o'), on = col('c.CustomerId')==col('o.CustomerId'), how = 'left').filter(col('o.OrderId').isNull()).select('CustomerName')\n",
    "cust.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952265d-dda5-4908-91fa-5d8415a57ca5",
   "metadata": {},
   "source": [
    "### Question 4 — Duplicate Numbers\n",
    "\n",
    "Using the `Logs` table, find all numbers that appear **at least three times consecutively**.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Order is determined by the natural insertion order.\n",
    "- Repeated values must be adjacent to count.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- `ConsecutiveNums`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703c2d42-f744-44f0-93da-ff399dd18de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|LogId|\n",
      "+-----+\n",
      "|    1|\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "|    3|\n",
      "|    3|\n",
      "|    5|\n",
      "|    6|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Logs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b86481-76e4-4fe1-bd56-347270c6d49a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ConsecutiveNums|\n",
      "+---------------+\n",
      "|              3|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log = Logs.withColumn('Lag', lag(col('LogId')).over(Window.orderBy(col('LogId')))).withColumn('Lead', lead(col('LogId')).over(Window.orderBy(col('LogId'))))\n",
    "log.filter((col('LogId')==col('Lag')) & (col('Lead') == col('LogId'))).selectExpr('LogId as ConsecutiveNums').drop('Lag','Lead').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78008ca9-cc34-4c89-a52c-1bf9d89be2a8",
   "metadata": {},
   "source": [
    "### Question 5 — High Attendance Periods\n",
    "\n",
    "From the `Stadium` table, report all rows that belong to a period of **at least three consecutive days** where `People >= 100`.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- All qualifying rows in the streak must be returned.\n",
    "- Single-day spikes should be excluded.\n",
    "\n",
    "Expected columns:\n",
    "\n",
    "- `VisitDate`, `People`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "824e6f3a-f993-4621-bbd0-d21ec5991288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "| VisitDate|People|\n",
      "+----------+------+\n",
      "|2024-01-01|    10|\n",
      "|2024-01-02|   120|\n",
      "|2024-01-03|   130|\n",
      "|2024-01-04|   140|\n",
      "|2024-01-05|    20|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Stadium.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08a587ee-fb8e-4685-b39f-fd8e17bd2824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "| VisitDate|People|\n",
      "+----------+------+\n",
      "|2024-01-02|   120|\n",
      "|2024-01-03|   130|\n",
      "|2024-01-04|   140|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stad = Stadium.withColumn('prev_day_count',lag('People').over(Window.orderBy('VisitDate')))\\\n",
    "        .withColumn('next_day_count', lead('People').over(Window.orderBy('VisitDate')))\\\n",
    "        .where('(prev_day_count<100 and People>=100) OR (People>=100 and next_day_count>=100) OR (People>=100 and next_day_count<100)')\\\n",
    "        .select('VisitDate','People')\n",
    "stad.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57b23e-7f49-43d2-956f-f715fa7074f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
